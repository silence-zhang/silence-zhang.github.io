# Practical Deep Learning

Here's the table of contents:

1. TOC
{:toc}

## Machine Learning(ML)

The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps.

## Neural Network(NN)

A neural network is a system of artificial neurons that are connected to each other in a way that allows them to learn and recognize patterns.

![p1](/images/Pastedimage20240314180458.png)

## Parallel Distributed Processing(PDP)

- A set of processing units
- A state of activation
- An output function for each unit
- A pattern of connectivity among units
- A propagation rule for propagating patterns of activities through the network of connectivities
- An activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit
- A learning rule whereby patterns of connectivity are modified by experience
- An environment within which the system must operate

## Stochastic Gradient Descent([SGD: 随机梯度下降](https://zh.d2l.ai/chapter_optimization/sgd.html))

Neural networks are special because they are highly flexible, which means they can solve an unusually wide range of problems just by finding the right weights. This is powerful, because stochastic gradient descent provides us a way to find those weight values automatically.

![p1](/images/WX20240322-120021@2x.png)

### Backward pass and Forward pass

The forward pass is the process of feeding data through the network, and the backward pass is the process of propagating errors back through the network.

### Learning Rate and Stepping

The learning rate is often a number between 0.001 and 0.1. It’s the amount by which the weights are adjusted during each iteration of the training loop.
Once you’ve picked a learning rate, you can adjust your parameters using this simple function:

``` python
w -= w.grad * lr
```

This is known as stepping your parameters, using an optimization step.

![p](/images/WX20240322-151036@2x.png)

![p](/images/WX20240322-151049@2x.png)

![p](/images/WX20240322-151105@2x.png)

## Training Loop

![p2](/images/Pastedimage20240315111753.png)

## Feedback Loops

- A *`predictive policing`* model is created based on where arrests have been made in the past. In practice, this is not actually predicting crime, but rather predicting arrests, and is therefore partially simply reflecting biases in existing policing processes.
- Law enforcement officers then might use that model to decide where to focus their policing activity, resulting in increased arrests in those areas.
- Data on these additional arrests would then be fed back in to retrain future versions of the model.

## Classification and Regression

A classification model is one that attempts to predict a class, or category. That is, it’s predicting from a number of discrete possibilities, such as “dog” or “cat.”
A regression model is one that attempts to predict one or more numeric quantities, such as a temperature or a location.

## Overfitting and Underfitting

confirmed that overfitting is occurring (i.e., if you have observed the validation accuracy getting worse during training).

![p3](/images/Pastedimage20240315115211.png)

## Convolutional Neural Network (CNN)

## Pre-trained Model

A model that has weights that have already been trained on another dataset is called a *pre‐trained* model.

## Transfer Model

Using a pretrained model for a task different from what it was originally trained for.

## Fine-Tuning(adapt a pre-trained model for a new dataset)

A transfer learning technique that updates the parameters of a pre‐ trained model by training for additional epochs using a different task from that used for pretraining.

## Deep Learning Vocabulary

![p4](/images/Pastedimage20240315144530.png)

## Training Sets && Validation Sets && Test Sets

- Training data is fully exposed
- Validation data is less exposed
- Test data is totally hidden

## Independent Variables && Dependent Variables

The independent variable is the thing we are using to make predictions from, and the dependent variable is our target.

## Data Augmentation

Data augmentation refers to creating random variations of our input data, such that they appear different but do not change the meaning of the data.

## Out-Of-Domain data

That is to say, there may be data that our model sees in production that is very different from what it saw during training.

## Domain Shift

This is when the type of data changes gradually over time. For example, an insurance company is using a deep learning model as part of their pricing algorithm, but over time their customers will be different, with the original training data not being representative of current data, and the deep learning model being applied on effectively out-of-domain data.

## Confusion Matrix

![p4](/images/Pastedimage20240320104843.png)

## Data Ethics

- *Recourse and accountability*(追责和问责)
- *Feedback loops*
- *Bias*
- *Disinformation*

## L1 norm and L2 norm and MSE(mean square error)

The L1 norm is the sum of the absolute values of the elements of a vector.
The L2 norm is the square root of the sum of the squares of the elements of a vector.
The MSE is the mean squared error.

## NumPy Arrays and PyTorch Tensors

NumPy is the most widely used library for scientific and numeric programming in Python. It provides similar functionality and a similar API to that provided by PyTorch; however, it does not support using the GPU or calculating gradients, which are both critical for deep learning. *NumPy arrays and PyTorch tensors can finish computations many thousands of times faster than using pure Python.*

`A NumPy array is a multidimensional table of data, with all items of the same type. Since that can be any type at all, they can even be arrays of arrays, with the innermost arrays potentially being different sizes—this is called a jagged array.`
`A PyTorch tensor is nearly the same thing as a NumPy array, but with an additional restriction that unlocks additional capabilities. The restriction is that a tensor cannot use just any old type—it has to use a single basic numeric type for all components.`
